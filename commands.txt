#Create directory
[training@localhost Desktop]$ mkdir final_project
[training@localhost Desktop]$ cd final_project

#install python3 with pandas,requests,xlrd
[training@localhost final_project]$ cd /usr/src
[training@localhost final_project]$ wget https://www.python.org/ftp/python/3.6.9/Python-3.6.9.tgz
[training@localhost final_project]$ tar xzf Python-3.6.9.tgz
[training@localhost final_project]$ cd Python-3.6.9
[training@localhost final_project]$ ./configure --enable-optimizations
[training@localhost final_project]$ make install
[training@localhost final_project]$ python3.6 -V
[training@localhost final_project]$ sudo python3 -m pip install requests
[training@localhost final_project]$ sudo python3 -m pip install pandas
[training@localhost final_project]$ sudo python3 -m pip install xlrd

#run download script
[training@localhost final_project]$ python3 pull_data.py

##load data to hdfs
#[training@localhost final_project]$ hadoop fs -put consumer_confidence_index.csv
#[training@localhost final_project]$ hadoop fs -put consumer_credit.csv[training@localhost final_project]$ hadoop fs -put g17_industrial_production_and_cap_utilization.csv
#[training@localhost final_project]$ hadoop fs -put gdp_by_quarter.csv[training@localhost final_project]$ hadoop fs -put gdp_by_year.csv
#[training@localhost final_project]$ hadoop fs -put median_family_income.csv
#[training@localhost final_project]$ hadoop fs -put retail_trade.csv
##check files
#[training@localhost final_project]$ hadoop fs -ls

#load data to hdfs | switched to use json to make loading to pyspark simpler
[training@localhost final_project]$ hadoop fs -put consumer_confidence_index.json
[training@localhost final_project]$ hadoop fs -put consumer_credit.json[training@localhost final_project]$ hadoop fs -put g17_industrial_production_and_cap_utilization.json
[training@localhost final_project]$ hadoop fs -put gdp_by_quarter.json[training@localhost final_project]$ hadoop fs -put gdp_by_year.json
[training@localhost final_project]$ hadoop fs -put median_family_income.json
[training@localhost final_project]$ hadoop fs -put retail_trade.json
#check files
[training@localhost final_project]$ hadoop fs -ls

#start pyspark
[training@localhost final_project]$
